#!/usr/bin/env python3
"""
Ø¥Ø·Ø§Ø± Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„ ÙˆØ­Ù„ ÙØ±Ø¶ÙŠØ© Ø±ÙŠÙ…Ø§Ù†
ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù…ÙŠ ØµØ§Ø±Ù… Ù„Ù„Ø§Ø¯Ø¹Ø§Ø¡Ø§Øª ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬
"""

import numpy as np
import matplotlib.pyplot as plt
from typing import List, Tuple, Dict, Any
import time
import warnings
warnings.filterwarnings('ignore')

class RiemannHypothesisValidator:
    """ÙØ¦Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø­Ù„ ÙØ±Ø¶ÙŠØ© Ø±ÙŠÙ…Ø§Ù†"""
    
    def __init__(self):
        self.known_zeros = [
            14.1347251417346937904572519835625,
            21.0220396387715549926284795938969,
            25.0108575801456887632137909925628,
            30.4248761258595132103118975305239,
            32.9350615877391896906623689640542
        ]
        self.test_results = {}
        
    def test_dimensional_consistency(self) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ÙŠ Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª"""
        print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ÙŠ...")
        
        results = {}
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ø¯Ù„Ø© ÙƒØªÙ„Ø© Ø§Ù„ÙØªÙŠÙ„Ø©
        h = 6.62607015e-34  # [M LÂ² Tâ»Â¹]
        c = 299792458       # [L Tâ»Â¹]
        
        # Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: mâ‚€ = h/(4Ï€cÂ²)
        # Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: [M LÂ² Tâ»Â¹] / [LÂ² Tâ»Â²] = [M T] âŒ
        original_dims = "[M T]"  # Ø®Ø·Ø£ Ø£Ø¨Ø¹Ø§Ø¯ÙŠ
        
        # Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ù…ØµØ­Ø­Ø©: mâ‚€ = h/(4Ï€cÂ·râ‚€)
        # Ù†Ø­ØªØ§Ø¬ râ‚€ Ø¨ÙˆØ­Ø¯Ø© [L] Ù„Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ [M]
        r0_needed = "[L]"
        corrected_dims = "[M]"  # ØµØ­ÙŠØ­ Ø£Ø¨Ø¹Ø§Ø¯ÙŠØ§Ù‹
        
        results['mass_equation'] = {
            'original_correct': False,
            'original_dimensions': original_dims,
            'corrected_correct': True,
            'corrected_dimensions': corrected_dims,
            'r0_requirement': r0_needed
        }
        
        return results
    
    def test_rlc_consistency(self) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§ØªØ³Ø§Ù‚ Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø¯ÙˆØ§Ø¦Ø± RLC"""
        print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§ØªØ³Ø§Ù‚ Ø¯ÙˆØ§Ø¦Ø± RLC...")
        
        results = {}
        test_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
        
        for p in test_primes:
            R = np.sqrt(p)
            L = 1 / (4 * p**(3/2))
            C = 1 / np.sqrt(p)
            
            # Ø´Ø±Ø· Ø§Ù„Ø±Ù†ÙŠÙ†: Ï‰â‚€ = 1/âˆš(LC)
            omega_0 = 1 / np.sqrt(L * C)
            expected_omega = 2 * p
            
            error = abs(omega_0 - expected_omega) / expected_omega
            
            results[f'prime_{p}'] = {
                'R': R,
                'L': L,
                'C': C,
                'omega_calculated': omega_0,
                'omega_expected': expected_omega,
                'relative_error': error,
                'consistent': error < 1e-10
            }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        all_consistent = all(results[key]['consistent'] for key in results)
        avg_error = np.mean([results[key]['relative_error'] for key in results])
        
        results['summary'] = {
            'all_consistent': all_consistent,
            'average_error': avg_error,
            'max_error': max([results[key]['relative_error'] for key in results])
        }
        
        return results
    
    def test_vector_path_closure(self, s: complex, max_terms: int = 10000) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…ØªØ¬Ù‡ÙŠ"""
        print(f"ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ø³Ø§Ø± Ø¹Ù†Ø¯ s = {s}...")
        
        current_pos = 0 + 0j
        path = [current_pos]
        
        for n in range(1, max_terms + 1):
            term = 1 / (n**s)
            current_pos += term
            path.append(current_pos)
            
            # ØªÙˆÙ‚Ù Ù…Ø¨ÙƒØ± Ø¥Ø°Ø§ ØªØ¨Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³Ø§Ø± ÙƒØ«ÙŠØ±Ø§Ù‹
            if abs(current_pos) > 1000:
                break
        
        final_position = path[-1]
        closure_error = abs(final_position)
        
        return {
            'final_position': final_position,
            'closure_error': closure_error,
            'path_length': len(path),
            'converged': closure_error < 1e-3,
            'path_sample': path[::len(path)//10] if len(path) > 10 else path
        }
    
    def test_known_zeros(self) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£ØµÙØ§Ø± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© Ù„Ø¯Ø§Ù„Ø© Ø²ÙŠØªØ§"""
        print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£ØµÙØ§Ø± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©...")
        
        results = {}
        
        for i, t in enumerate(self.known_zeros):
            s = 0.5 + 1j * t
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ø³Ø§Ø±
            path_result = self.test_vector_path_closure(s)
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø£Ù†Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø· Ø§Ù„Ø­Ø±Ø¬
            on_critical_line = abs(s.real - 0.5) < 1e-10
            
            results[f'zero_{i+1}'] = {
                't': t,
                's': s,
                'on_critical_line': on_critical_line,
                'path_closure': path_result,
                'valid_zero': path_result['converged'] and on_critical_line
            }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        valid_count = sum(1 for key in results if results[key]['valid_zero'])
        total_count = len(results)
        
        results['summary'] = {
            'valid_zeros': valid_count,
            'total_tested': total_count,
            'success_rate': valid_count / total_count,
            'all_valid': valid_count == total_count
        }
        
        return results
    
    def test_off_critical_line(self) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù‚Ø§Ø· Ø®Ø§Ø±Ø¬ Ø§Ù„Ø®Ø· Ø§Ù„Ø­Ø±Ø¬"""
        print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù‚Ø§Ø· Ø®Ø§Ø±Ø¬ Ø§Ù„Ø®Ø· Ø§Ù„Ø­Ø±Ø¬...")
        
        results = {}
        test_points = [
            0.6 + 14.1347j,  # Ù†ÙØ³ t Ù„Ù„ØµÙØ± Ø§Ù„Ø£ÙˆÙ„ Ù„ÙƒÙ† Ïƒ â‰  0.5
            0.7 + 21.0220j,  # Ù†ÙØ³ t Ù„Ù„ØµÙØ± Ø§Ù„Ø«Ø§Ù†ÙŠ Ù„ÙƒÙ† Ïƒ â‰  0.5
            0.4 + 25.0109j,  # Ù†ÙØ³ t Ù„Ù„ØµÙØ± Ø§Ù„Ø«Ø§Ù„Ø« Ù„ÙƒÙ† Ïƒ â‰  0.5
            0.8 + 15.0000j,  # Ù†Ù‚Ø·Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
            0.3 + 20.0000j   # Ù†Ù‚Ø·Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø£Ø®Ø±Ù‰
        ]
        
        for i, s in enumerate(test_points):
            path_result = self.test_vector_path_closure(s, max_terms=5000)
            
            results[f'point_{i+1}'] = {
                's': s,
                'sigma': s.real,
                't': s.imag,
                'path_closure': path_result,
                'appears_zero': path_result['converged']
            }
        
        # Ù‡Ù„ ÙˆØ¬Ø¯Ù†Ø§ Ø£ÙŠ "Ø£ØµÙØ§Ø±" Ø®Ø§Ø±Ø¬ Ø§Ù„Ø®Ø· Ø§Ù„Ø­Ø±Ø¬ØŸ
        false_zeros = sum(1 for key in results if results[key]['appears_zero'])
        
        results['summary'] = {
            'false_zeros_found': false_zeros,
            'total_tested': len(test_points),
            'hypothesis_violated': false_zeros > 0
        }
        
        return results
    
    def test_prime_prediction_accuracy(self) -> Dict[str, Any]:
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
        known_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 
                       53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113]
        
        def simple_prime_predictor(p):
            """Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„ØªÙ†Ø¨Ø¤ (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)"""
            # Ù‡Ø°Ù‡ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ø¨Ø³Ø·Ø© - ÙŠØ¬Ø¨ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ø¨Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ÙØ¹Ù„ÙŠØ©
            gap = int(2 + np.log(p))
            candidate = p + gap
            while not self.is_prime(candidate):
                candidate += 1
            return candidate
        
        results = {}
        correct_predictions = 0
        
        for i in range(len(known_primes) - 1):
            current_prime = known_primes[i]
            actual_next = known_primes[i + 1]
            predicted_next = simple_prime_predictor(current_prime)
            
            is_correct = predicted_next == actual_next
            if is_correct:
                correct_predictions += 1
            
            results[f'prediction_{i+1}'] = {
                'current_prime': current_prime,
                'actual_next': actual_next,
                'predicted_next': predicted_next,
                'correct': is_correct,
                'gap_actual': actual_next - current_prime,
                'gap_predicted': predicted_next - current_prime
            }
        
        accuracy = correct_predictions / (len(known_primes) - 1)
        
        results['summary'] = {
            'total_predictions': len(known_primes) - 1,
            'correct_predictions': correct_predictions,
            'accuracy': accuracy,
            'high_accuracy': accuracy > 0.9
        }
        
        return results
    
    def is_prime(self, n: int) -> bool:
        """ÙØ­Øµ Ø¨Ø³ÙŠØ· Ù„Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©"""
        if n < 2:
            return False
        if n == 2:
            return True
        if n % 2 == 0:
            return False
        for i in range(3, int(np.sqrt(n)) + 1, 2):
            if n % i == 0:
                return False
        return True
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„...")
        print("=" * 60)
        
        start_time = time.time()
        
        # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
        tests = {
            'dimensional_consistency': self.test_dimensional_consistency(),
            'rlc_consistency': self.test_rlc_consistency(),
            'known_zeros': self.test_known_zeros(),
            'off_critical_line': self.test_off_critical_line(),
            'prime_prediction': self.test_prime_prediction_accuracy()
        }
        
        end_time = time.time()
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        overall_results = self.analyze_overall_results(tests)
        overall_results['execution_time'] = end_time - start_time
        
        return {
            'individual_tests': tests,
            'overall_assessment': overall_results
        }
    
    def analyze_overall_results(self, tests: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©"""
        
        # ØªÙ‚ÙŠÙŠÙ… ÙƒÙ„ Ø§Ø®ØªØ¨Ø§Ø±
        assessments = {}
        
        # Ø§Ù„Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ÙŠ
        dim_test = tests['dimensional_consistency']
        assessments['dimensional'] = {
            'passed': dim_test['mass_equation']['corrected_correct'],
            'issues': ['Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„ÙƒØªÙ„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù‡Ø§ Ù…Ø´ÙƒÙ„Ø© Ø£Ø¨Ø¹Ø§Ø¯ÙŠØ©'] if not dim_test['mass_equation']['original_correct'] else []
        }
        
        # Ø§ØªØ³Ø§Ù‚ RLC
        rlc_test = tests['rlc_consistency']
        assessments['rlc'] = {
            'passed': rlc_test['summary']['all_consistent'],
            'average_error': rlc_test['summary']['average_error']
        }
        
        # Ø§Ù„Ø£ØµÙØ§Ø± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        zeros_test = tests['known_zeros']
        assessments['known_zeros'] = {
            'passed': zeros_test['summary']['all_valid'],
            'success_rate': zeros_test['summary']['success_rate']
        }
        
        # Ù†Ù‚Ø§Ø· Ø®Ø§Ø±Ø¬ Ø§Ù„Ø®Ø· Ø§Ù„Ø­Ø±Ø¬
        off_line_test = tests['off_critical_line']
        assessments['off_critical'] = {
            'passed': not off_line_test['summary']['hypothesis_violated'],
            'false_zeros': off_line_test['summary']['false_zeros_found']
        }
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        prime_test = tests['prime_prediction']
        assessments['prime_prediction'] = {
            'passed': prime_test['summary']['high_accuracy'],
            'accuracy': prime_test['summary']['accuracy']
        }
        
        # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        passed_tests = sum(1 for test in assessments.values() if test['passed'])
        total_tests = len(assessments)
        
        return {
            'individual_assessments': assessments,
            'tests_passed': passed_tests,
            'total_tests': total_tests,
            'overall_score': passed_tests / total_tests,
            'riemann_solved': passed_tests == total_tests and assessments['known_zeros']['success_rate'] == 1.0,
            'major_issues': self.identify_major_issues(assessments)
        }
    
    def identify_major_issues(self, assessments: Dict[str, Any]) -> List[str]:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        issues = []
        
        if not assessments['dimensional']['passed']:
            issues.append("Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„Ø§ØªØ³Ø§Ù‚ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ÙŠ Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª")
        
        if not assessments['known_zeros']['passed']:
            issues.append("ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£ØµÙØ§Ø± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©")
        
        if not assessments['off_critical']['passed']:
            issues.append("ÙˆØ¬ÙˆØ¯ Ø£ØµÙØ§Ø± Ù…Ø­ØªÙ…Ù„Ø© Ø®Ø§Ø±Ø¬ Ø§Ù„Ø®Ø· Ø§Ù„Ø­Ø±Ø¬")
        
        if assessments['prime_prediction']['accuracy'] < 0.5:
            issues.append("Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠØ©")
        
        return issues
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """Ø¥Ù†ØªØ§Ø¬ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        report = []
        report.append("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„")
        report.append("=" * 60)
        
        overall = results['overall_assessment']
        
        report.append(f"ğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {overall['tests_passed']}/{overall['total_tests']} ({overall['overall_score']:.1%})")
        report.append(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ°: {overall['execution_time']:.2f} Ø«Ø§Ù†ÙŠØ©")
        report.append("")
        
        # Ù‡Ù„ ØªÙ… Ø­Ù„ ÙØ±Ø¶ÙŠØ© Ø±ÙŠÙ…Ø§Ù†ØŸ
        if overall['riemann_solved']:
            report.append("âœ… Ø§Ù„Ù†ØªÙŠØ¬Ø©: ØªÙ… Ø­Ù„ ÙØ±Ø¶ÙŠØ© Ø±ÙŠÙ…Ø§Ù† Ø¨Ù†Ø¬Ø§Ø­!")
        else:
            report.append("âŒ Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù„Ù… ÙŠØªÙ… Ø­Ù„ ÙØ±Ø¶ÙŠØ© Ø±ÙŠÙ…Ø§Ù† Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„")
        
        report.append("")
        
        # Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        if overall['major_issues']:
            report.append("âš ï¸ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:")
            for issue in overall['major_issues']:
                report.append(f"  â€¢ {issue}")
        else:
            report.append("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø´Ø§ÙƒÙ„ Ø±Ø¦ÙŠØ³ÙŠØ©")
        
        report.append("")
        
        # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
        report.append("ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:")
        
        assessments = overall['individual_assessments']
        
        for test_name, assessment in assessments.items():
            status = "âœ…" if assessment['passed'] else "âŒ"
            report.append(f"  {status} {test_name}")
            
            if test_name == 'prime_prediction':
                report.append(f"      Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤: {assessment['accuracy']:.1%}")
            elif test_name == 'known_zeros':
                report.append(f"      Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {assessment['success_rate']:.1%}")
        
        return "\n".join(report)

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    validator = RiemannHypothesisValidator()
    
    print("ğŸ”¬ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ù„Ù…ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù†Ø¸Ø±ÙŠØ© Ø§Ù„ÙØªØ§Ø¦Ù„")
    print("=" * 60)
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    results = validator.run_comprehensive_test()
    
    # Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report = validator.generate_report(results)
    
    print("\n" + "=" * 60)
    print(report)
    print("=" * 60)
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    with open('/home/ubuntu/test_results.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    return results

if __name__ == "__main__":
    results = main()

